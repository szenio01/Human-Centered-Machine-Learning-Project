Obesity is a significant public health challenge globally, with a
rising prevalence in various countries. Understanding the underlying
factors contributing to different BMI categories is crucial for
developing effective interventions. This project explores various explainability
methods applied to different machine learning models
to identify key features influencing BMI categories in individuals.
We implemented Decision Trees, Random Forests, LightGBM,
RuleFit, Neural Networks, and Partial Dependence Plots to analyze
the data. Our approach included plotting feature importances, visualizing
model structures, and pruning the depth of trees for the
Decision Trees and Random Forests. Additionally, we generated
counterfactual explanations to provide insights into how slight
changes in input features could lead to different obesity outcomes.
The results indicate that the consumption of vegetables, Age,
and time spent using technological devices are the most relevant
features in most models. RuleFit provided a rule-based interpretation
and Counterfactual explanations highlighted that changes in
specific features could potentially reduce BMI, offering recommendations
for individuals.
By leveraging these diverse explainability methods, we provide
actionable insights into the critical factors contributing to obesity.
These findings can inform targeted interventions and policies aimed
at improving health outcomes in these populations..
